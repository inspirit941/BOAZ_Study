{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "과제4_test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "aeBCQqbAKqfB",
        "colab_type": "code",
        "outputId": "5f3193bd-eb0f-42fb-e3c9-750e05000a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "\n",
        "batch_size = 4\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 5\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.RandomRotation(20),\n",
        "                                transforms.RandomVerticalFlip(),transforms.Resize((224,224)),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "trainset = datasets.CIFAR100(root='./data', train=True, download=True,\n",
        "                                        transform=transform)\n",
        "\n",
        "testset = datasets.CIFAR100(root='./data', train=False, download=True, \n",
        "                                       transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kQ0jpOiGMW4L",
        "colab_type": "code",
        "outputId": "825bdd7b-b4d5-4766-c448-dfc3a030882c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(images[0].shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 224, 224])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sUPXh5skSrq6",
        "colab_type": "code",
        "outputId": "48813fc5-8efc-4988-b6a1-1acd18cbc035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "vgg16 = models.vgg16_bn(pretrained=True)\n",
        "\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "\n",
        "inception = models.inception_v3(pretrained=True)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.torch/models/vgg16_bn-6c64b313.pth\n",
            "553507836it [00:27, 19920433.85it/s]\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.torch/models/resnet18-5c106cde.pth\n",
            "46827520it [00:02, 16614416.61it/s]\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.torch/models/inception_v3_google-1a9a5a14.pth\n",
            "108857766it [00:01, 78389799.56it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "eN8sgu8RTx1I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "vgg16 = vgg16.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5s28RRWqTClR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IzBpmN78TCYd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "U8-UN9FSKsHN",
        "colab_type": "code",
        "outputId": "139540f7-2c5a-476f-b2b6-88cb69e79cbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10642
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Loss Function\n",
        "Loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(vgg16.parameters(), lr=learning_rate)\n",
        "\n",
        "vgg16.children\n",
        "\n",
        "# Train the model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      \n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = vgg16(images)\n",
        "        loss = Loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('Epoch [%d/%d], Iter [%d/%d] Loss %.4f'\n",
        "                  % (epoch+1, num_epochs, i, len(train_loader), loss.item()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Iter [0/12500] Loss 9.7729\n",
            "Epoch [1/5], Iter [100/12500] Loss 5.3520\n",
            "Epoch [1/5], Iter [200/12500] Loss 4.7307\n",
            "Epoch [1/5], Iter [300/12500] Loss 5.4555\n",
            "Epoch [1/5], Iter [400/12500] Loss 4.9639\n",
            "Epoch [1/5], Iter [500/12500] Loss 4.0750\n",
            "Epoch [1/5], Iter [600/12500] Loss 4.7685\n",
            "Epoch [1/5], Iter [700/12500] Loss 4.4075\n",
            "Epoch [1/5], Iter [800/12500] Loss 4.4773\n",
            "Epoch [1/5], Iter [900/12500] Loss 4.3723\n",
            "Epoch [1/5], Iter [1000/12500] Loss 4.6358\n",
            "Epoch [1/5], Iter [1100/12500] Loss 3.6691\n",
            "Epoch [1/5], Iter [1200/12500] Loss 3.5593\n",
            "Epoch [1/5], Iter [1300/12500] Loss 5.1254\n",
            "Epoch [1/5], Iter [1400/12500] Loss 4.1564\n",
            "Epoch [1/5], Iter [1500/12500] Loss 3.9458\n",
            "Epoch [1/5], Iter [1600/12500] Loss 3.5899\n",
            "Epoch [1/5], Iter [1700/12500] Loss 3.1420\n",
            "Epoch [1/5], Iter [1800/12500] Loss 3.4606\n",
            "Epoch [1/5], Iter [1900/12500] Loss 3.5236\n",
            "Epoch [1/5], Iter [2000/12500] Loss 4.5900\n",
            "Epoch [1/5], Iter [2100/12500] Loss 3.0508\n",
            "Epoch [1/5], Iter [2200/12500] Loss 3.5370\n",
            "Epoch [1/5], Iter [2300/12500] Loss 3.7759\n",
            "Epoch [1/5], Iter [2400/12500] Loss 3.5573\n",
            "Epoch [1/5], Iter [2500/12500] Loss 3.5445\n",
            "Epoch [1/5], Iter [2600/12500] Loss 4.1932\n",
            "Epoch [1/5], Iter [2700/12500] Loss 4.3856\n",
            "Epoch [1/5], Iter [2800/12500] Loss 3.9551\n",
            "Epoch [1/5], Iter [2900/12500] Loss 3.7616\n",
            "Epoch [1/5], Iter [3000/12500] Loss 3.8022\n",
            "Epoch [1/5], Iter [3100/12500] Loss 2.9420\n",
            "Epoch [1/5], Iter [3200/12500] Loss 5.1027\n",
            "Epoch [1/5], Iter [3300/12500] Loss 4.4051\n",
            "Epoch [1/5], Iter [3400/12500] Loss 4.2296\n",
            "Epoch [1/5], Iter [3500/12500] Loss 3.8273\n",
            "Epoch [1/5], Iter [3600/12500] Loss 3.8460\n",
            "Epoch [1/5], Iter [3700/12500] Loss 2.8231\n",
            "Epoch [1/5], Iter [3800/12500] Loss 2.6913\n",
            "Epoch [1/5], Iter [3900/12500] Loss 2.5175\n",
            "Epoch [1/5], Iter [4000/12500] Loss 2.2835\n",
            "Epoch [1/5], Iter [4100/12500] Loss 2.2738\n",
            "Epoch [1/5], Iter [4200/12500] Loss 2.2853\n",
            "Epoch [1/5], Iter [4300/12500] Loss 4.2145\n",
            "Epoch [1/5], Iter [4400/12500] Loss 3.4515\n",
            "Epoch [1/5], Iter [4500/12500] Loss 3.1598\n",
            "Epoch [1/5], Iter [4600/12500] Loss 2.4677\n",
            "Epoch [1/5], Iter [4700/12500] Loss 2.8607\n",
            "Epoch [1/5], Iter [4800/12500] Loss 3.2564\n",
            "Epoch [1/5], Iter [4900/12500] Loss 2.1979\n",
            "Epoch [1/5], Iter [5000/12500] Loss 2.9427\n",
            "Epoch [1/5], Iter [5100/12500] Loss 5.2457\n",
            "Epoch [1/5], Iter [5200/12500] Loss 1.7828\n",
            "Epoch [1/5], Iter [5300/12500] Loss 2.5519\n",
            "Epoch [1/5], Iter [5400/12500] Loss 1.5227\n",
            "Epoch [1/5], Iter [5500/12500] Loss 2.3693\n",
            "Epoch [1/5], Iter [5600/12500] Loss 4.0706\n",
            "Epoch [1/5], Iter [5700/12500] Loss 2.3603\n",
            "Epoch [1/5], Iter [5800/12500] Loss 2.8229\n",
            "Epoch [1/5], Iter [5900/12500] Loss 2.2620\n",
            "Epoch [1/5], Iter [6000/12500] Loss 2.7690\n",
            "Epoch [1/5], Iter [6100/12500] Loss 3.0141\n",
            "Epoch [1/5], Iter [6200/12500] Loss 2.5271\n",
            "Epoch [1/5], Iter [6300/12500] Loss 3.0583\n",
            "Epoch [1/5], Iter [6400/12500] Loss 2.0731\n",
            "Epoch [1/5], Iter [6500/12500] Loss 3.6751\n",
            "Epoch [1/5], Iter [6600/12500] Loss 2.4887\n",
            "Epoch [1/5], Iter [6700/12500] Loss 3.3428\n",
            "Epoch [1/5], Iter [6800/12500] Loss 4.0957\n",
            "Epoch [1/5], Iter [6900/12500] Loss 3.2445\n",
            "Epoch [1/5], Iter [7000/12500] Loss 3.4696\n",
            "Epoch [1/5], Iter [7100/12500] Loss 2.9614\n",
            "Epoch [1/5], Iter [7200/12500] Loss 1.6588\n",
            "Epoch [1/5], Iter [7300/12500] Loss 1.6360\n",
            "Epoch [1/5], Iter [7400/12500] Loss 3.5917\n",
            "Epoch [1/5], Iter [7500/12500] Loss 3.0038\n",
            "Epoch [1/5], Iter [7600/12500] Loss 1.4072\n",
            "Epoch [1/5], Iter [7700/12500] Loss 2.3057\n",
            "Epoch [1/5], Iter [7800/12500] Loss 1.6068\n",
            "Epoch [1/5], Iter [7900/12500] Loss 3.5675\n",
            "Epoch [1/5], Iter [8000/12500] Loss 3.6970\n",
            "Epoch [1/5], Iter [8100/12500] Loss 1.4168\n",
            "Epoch [1/5], Iter [8200/12500] Loss 2.1477\n",
            "Epoch [1/5], Iter [8300/12500] Loss 2.5220\n",
            "Epoch [1/5], Iter [8400/12500] Loss 4.5268\n",
            "Epoch [1/5], Iter [8500/12500] Loss 3.6440\n",
            "Epoch [1/5], Iter [8600/12500] Loss 2.1634\n",
            "Epoch [1/5], Iter [8700/12500] Loss 3.2836\n",
            "Epoch [1/5], Iter [8800/12500] Loss 0.9424\n",
            "Epoch [1/5], Iter [8900/12500] Loss 2.4552\n",
            "Epoch [1/5], Iter [9000/12500] Loss 3.7930\n",
            "Epoch [1/5], Iter [9100/12500] Loss 2.5497\n",
            "Epoch [1/5], Iter [9200/12500] Loss 1.9220\n",
            "Epoch [1/5], Iter [9300/12500] Loss 1.6874\n",
            "Epoch [1/5], Iter [9400/12500] Loss 3.1117\n",
            "Epoch [1/5], Iter [9500/12500] Loss 1.8697\n",
            "Epoch [1/5], Iter [9600/12500] Loss 2.3265\n",
            "Epoch [1/5], Iter [9700/12500] Loss 1.1154\n",
            "Epoch [1/5], Iter [9800/12500] Loss 3.9683\n",
            "Epoch [1/5], Iter [9900/12500] Loss 1.0090\n",
            "Epoch [1/5], Iter [10000/12500] Loss 3.2427\n",
            "Epoch [1/5], Iter [10100/12500] Loss 3.0369\n",
            "Epoch [1/5], Iter [10200/12500] Loss 4.1435\n",
            "Epoch [1/5], Iter [10300/12500] Loss 2.1937\n",
            "Epoch [1/5], Iter [10400/12500] Loss 2.9941\n",
            "Epoch [1/5], Iter [10500/12500] Loss 2.0261\n",
            "Epoch [1/5], Iter [10600/12500] Loss 1.5393\n",
            "Epoch [1/5], Iter [10700/12500] Loss 1.8878\n",
            "Epoch [1/5], Iter [10800/12500] Loss 2.6189\n",
            "Epoch [1/5], Iter [10900/12500] Loss 3.4904\n",
            "Epoch [1/5], Iter [11000/12500] Loss 2.0311\n",
            "Epoch [1/5], Iter [11100/12500] Loss 3.3090\n",
            "Epoch [1/5], Iter [11200/12500] Loss 3.5949\n",
            "Epoch [1/5], Iter [11300/12500] Loss 2.9486\n",
            "Epoch [1/5], Iter [11400/12500] Loss 2.5910\n",
            "Epoch [1/5], Iter [11500/12500] Loss 3.5417\n",
            "Epoch [1/5], Iter [11600/12500] Loss 3.3820\n",
            "Epoch [1/5], Iter [11700/12500] Loss 2.7887\n",
            "Epoch [1/5], Iter [11800/12500] Loss 1.6927\n",
            "Epoch [1/5], Iter [11900/12500] Loss 2.4395\n",
            "Epoch [1/5], Iter [12000/12500] Loss 2.8988\n",
            "Epoch [1/5], Iter [12100/12500] Loss 2.7819\n",
            "Epoch [1/5], Iter [12200/12500] Loss 4.5167\n",
            "Epoch [1/5], Iter [12300/12500] Loss 2.6534\n",
            "Epoch [1/5], Iter [12400/12500] Loss 3.2066\n",
            "Epoch [2/5], Iter [0/12500] Loss 1.3368\n",
            "Epoch [2/5], Iter [100/12500] Loss 1.1034\n",
            "Epoch [2/5], Iter [200/12500] Loss 2.6945\n",
            "Epoch [2/5], Iter [300/12500] Loss 3.2461\n",
            "Epoch [2/5], Iter [400/12500] Loss 2.5073\n",
            "Epoch [2/5], Iter [500/12500] Loss 1.5987\n",
            "Epoch [2/5], Iter [600/12500] Loss 2.3357\n",
            "Epoch [2/5], Iter [700/12500] Loss 1.2974\n",
            "Epoch [2/5], Iter [800/12500] Loss 2.9159\n",
            "Epoch [2/5], Iter [900/12500] Loss 2.0629\n",
            "Epoch [2/5], Iter [1000/12500] Loss 2.4862\n",
            "Epoch [2/5], Iter [1100/12500] Loss 4.1951\n",
            "Epoch [2/5], Iter [1200/12500] Loss 2.8610\n",
            "Epoch [2/5], Iter [1300/12500] Loss 2.3130\n",
            "Epoch [2/5], Iter [1400/12500] Loss 3.0422\n",
            "Epoch [2/5], Iter [1500/12500] Loss 2.7286\n",
            "Epoch [2/5], Iter [1600/12500] Loss 1.8498\n",
            "Epoch [2/5], Iter [1700/12500] Loss 2.7733\n",
            "Epoch [2/5], Iter [1800/12500] Loss 1.9494\n",
            "Epoch [2/5], Iter [1900/12500] Loss 2.8012\n",
            "Epoch [2/5], Iter [2000/12500] Loss 2.5912\n",
            "Epoch [2/5], Iter [2100/12500] Loss 1.2233\n",
            "Epoch [2/5], Iter [2200/12500] Loss 3.6729\n",
            "Epoch [2/5], Iter [2300/12500] Loss 2.0949\n",
            "Epoch [2/5], Iter [2400/12500] Loss 3.7042\n",
            "Epoch [2/5], Iter [2500/12500] Loss 1.8952\n",
            "Epoch [2/5], Iter [2600/12500] Loss 2.1021\n",
            "Epoch [2/5], Iter [2700/12500] Loss 2.1126\n",
            "Epoch [2/5], Iter [2800/12500] Loss 3.5623\n",
            "Epoch [2/5], Iter [2900/12500] Loss 1.5416\n",
            "Epoch [2/5], Iter [3000/12500] Loss 1.0410\n",
            "Epoch [2/5], Iter [3100/12500] Loss 0.9709\n",
            "Epoch [2/5], Iter [3200/12500] Loss 1.8901\n",
            "Epoch [2/5], Iter [3300/12500] Loss 2.3258\n",
            "Epoch [2/5], Iter [3400/12500] Loss 3.2392\n",
            "Epoch [2/5], Iter [3500/12500] Loss 2.4856\n",
            "Epoch [2/5], Iter [3600/12500] Loss 2.3145\n",
            "Epoch [2/5], Iter [3700/12500] Loss 3.1153\n",
            "Epoch [2/5], Iter [3800/12500] Loss 0.1160\n",
            "Epoch [2/5], Iter [3900/12500] Loss 4.4254\n",
            "Epoch [2/5], Iter [4000/12500] Loss 2.0010\n",
            "Epoch [2/5], Iter [4100/12500] Loss 2.9317\n",
            "Epoch [2/5], Iter [4200/12500] Loss 2.5212\n",
            "Epoch [2/5], Iter [4300/12500] Loss 3.0277\n",
            "Epoch [2/5], Iter [4400/12500] Loss 3.3794\n",
            "Epoch [2/5], Iter [4500/12500] Loss 1.6853\n",
            "Epoch [2/5], Iter [4600/12500] Loss 2.7901\n",
            "Epoch [2/5], Iter [4700/12500] Loss 1.5704\n",
            "Epoch [2/5], Iter [4800/12500] Loss 1.4381\n",
            "Epoch [2/5], Iter [4900/12500] Loss 2.3530\n",
            "Epoch [2/5], Iter [5000/12500] Loss 2.8302\n",
            "Epoch [2/5], Iter [5100/12500] Loss 1.4447\n",
            "Epoch [2/5], Iter [5200/12500] Loss 2.5409\n",
            "Epoch [2/5], Iter [5300/12500] Loss 2.1543\n",
            "Epoch [2/5], Iter [5400/12500] Loss 2.0284\n",
            "Epoch [2/5], Iter [5500/12500] Loss 1.9459\n",
            "Epoch [2/5], Iter [5600/12500] Loss 2.0753\n",
            "Epoch [2/5], Iter [5700/12500] Loss 2.9053\n",
            "Epoch [2/5], Iter [5800/12500] Loss 1.1902\n",
            "Epoch [2/5], Iter [5900/12500] Loss 1.5302\n",
            "Epoch [2/5], Iter [6000/12500] Loss 2.1601\n",
            "Epoch [2/5], Iter [6100/12500] Loss 2.0385\n",
            "Epoch [2/5], Iter [6200/12500] Loss 2.0249\n",
            "Epoch [2/5], Iter [6300/12500] Loss 1.8948\n",
            "Epoch [2/5], Iter [6400/12500] Loss 1.9906\n",
            "Epoch [2/5], Iter [6500/12500] Loss 3.0489\n",
            "Epoch [2/5], Iter [6600/12500] Loss 3.3839\n",
            "Epoch [2/5], Iter [6700/12500] Loss 0.8162\n",
            "Epoch [2/5], Iter [6800/12500] Loss 2.9015\n",
            "Epoch [2/5], Iter [6900/12500] Loss 3.5611\n",
            "Epoch [2/5], Iter [7000/12500] Loss 3.5035\n",
            "Epoch [2/5], Iter [7100/12500] Loss 1.6633\n",
            "Epoch [2/5], Iter [7200/12500] Loss 2.8918\n",
            "Epoch [2/5], Iter [7300/12500] Loss 2.3838\n",
            "Epoch [2/5], Iter [7400/12500] Loss 1.9371\n",
            "Epoch [2/5], Iter [7500/12500] Loss 2.6229\n",
            "Epoch [2/5], Iter [7600/12500] Loss 2.3774\n",
            "Epoch [2/5], Iter [7700/12500] Loss 2.9199\n",
            "Epoch [2/5], Iter [7800/12500] Loss 1.3838\n",
            "Epoch [2/5], Iter [7900/12500] Loss 2.1217\n",
            "Epoch [2/5], Iter [8000/12500] Loss 3.9256\n",
            "Epoch [2/5], Iter [8100/12500] Loss 3.2647\n",
            "Epoch [2/5], Iter [8200/12500] Loss 2.0934\n",
            "Epoch [2/5], Iter [8300/12500] Loss 3.6312\n",
            "Epoch [2/5], Iter [8400/12500] Loss 2.2539\n",
            "Epoch [2/5], Iter [8500/12500] Loss 2.7165\n",
            "Epoch [2/5], Iter [8600/12500] Loss 0.8648\n",
            "Epoch [2/5], Iter [8700/12500] Loss 0.6709\n",
            "Epoch [2/5], Iter [8800/12500] Loss 2.5417\n",
            "Epoch [2/5], Iter [8900/12500] Loss 1.5789\n",
            "Epoch [2/5], Iter [9000/12500] Loss 2.6646\n",
            "Epoch [2/5], Iter [9100/12500] Loss 0.5996\n",
            "Epoch [2/5], Iter [9200/12500] Loss 2.7497\n",
            "Epoch [2/5], Iter [9300/12500] Loss 2.5295\n",
            "Epoch [2/5], Iter [9400/12500] Loss 2.3272\n",
            "Epoch [2/5], Iter [9500/12500] Loss 0.9979\n",
            "Epoch [2/5], Iter [9600/12500] Loss 1.2253\n",
            "Epoch [2/5], Iter [9700/12500] Loss 1.3567\n",
            "Epoch [2/5], Iter [9800/12500] Loss 0.9191\n",
            "Epoch [2/5], Iter [9900/12500] Loss 1.6966\n",
            "Epoch [2/5], Iter [10000/12500] Loss 3.4562\n",
            "Epoch [2/5], Iter [10100/12500] Loss 2.6741\n",
            "Epoch [2/5], Iter [10200/12500] Loss 3.0241\n",
            "Epoch [2/5], Iter [10300/12500] Loss 0.8060\n",
            "Epoch [2/5], Iter [10400/12500] Loss 2.0471\n",
            "Epoch [2/5], Iter [10500/12500] Loss 2.6169\n",
            "Epoch [2/5], Iter [10600/12500] Loss 3.0830\n",
            "Epoch [2/5], Iter [10700/12500] Loss 3.2609\n",
            "Epoch [2/5], Iter [10800/12500] Loss 1.5490\n",
            "Epoch [2/5], Iter [10900/12500] Loss 2.1993\n",
            "Epoch [2/5], Iter [11000/12500] Loss 1.6769\n",
            "Epoch [2/5], Iter [11100/12500] Loss 2.0296\n",
            "Epoch [2/5], Iter [11200/12500] Loss 1.9274\n",
            "Epoch [2/5], Iter [11300/12500] Loss 1.5462\n",
            "Epoch [2/5], Iter [11400/12500] Loss 0.8782\n",
            "Epoch [2/5], Iter [11500/12500] Loss 0.3703\n",
            "Epoch [2/5], Iter [11600/12500] Loss 3.0365\n",
            "Epoch [2/5], Iter [11700/12500] Loss 3.4593\n",
            "Epoch [2/5], Iter [11800/12500] Loss 2.2350\n",
            "Epoch [2/5], Iter [11900/12500] Loss 3.3302\n",
            "Epoch [2/5], Iter [12000/12500] Loss 2.5719\n",
            "Epoch [2/5], Iter [12100/12500] Loss 3.1504\n",
            "Epoch [2/5], Iter [12200/12500] Loss 1.4331\n",
            "Epoch [2/5], Iter [12300/12500] Loss 1.2088\n",
            "Epoch [2/5], Iter [12400/12500] Loss 1.7700\n",
            "Epoch [3/5], Iter [0/12500] Loss 0.5812\n",
            "Epoch [3/5], Iter [100/12500] Loss 3.9590\n",
            "Epoch [3/5], Iter [200/12500] Loss 1.2150\n",
            "Epoch [3/5], Iter [300/12500] Loss 2.5519\n",
            "Epoch [3/5], Iter [400/12500] Loss 2.8901\n",
            "Epoch [3/5], Iter [500/12500] Loss 2.4890\n",
            "Epoch [3/5], Iter [600/12500] Loss 0.8277\n",
            "Epoch [3/5], Iter [700/12500] Loss 0.2909\n",
            "Epoch [3/5], Iter [800/12500] Loss 2.1669\n",
            "Epoch [3/5], Iter [900/12500] Loss 1.8205\n",
            "Epoch [3/5], Iter [1000/12500] Loss 1.9384\n",
            "Epoch [3/5], Iter [1100/12500] Loss 4.4815\n",
            "Epoch [3/5], Iter [1200/12500] Loss 0.7469\n",
            "Epoch [3/5], Iter [1300/12500] Loss 0.9814\n",
            "Epoch [3/5], Iter [1400/12500] Loss 3.2330\n",
            "Epoch [3/5], Iter [1500/12500] Loss 4.2217\n",
            "Epoch [3/5], Iter [1600/12500] Loss 3.4357\n",
            "Epoch [3/5], Iter [1700/12500] Loss 3.0226\n",
            "Epoch [3/5], Iter [1800/12500] Loss 3.0888\n",
            "Epoch [3/5], Iter [1900/12500] Loss 2.2236\n",
            "Epoch [3/5], Iter [2000/12500] Loss 1.8866\n",
            "Epoch [3/5], Iter [2100/12500] Loss 2.2151\n",
            "Epoch [3/5], Iter [2200/12500] Loss 1.1791\n",
            "Epoch [3/5], Iter [2300/12500] Loss 2.0505\n",
            "Epoch [3/5], Iter [2400/12500] Loss 1.0485\n",
            "Epoch [3/5], Iter [2500/12500] Loss 1.7524\n",
            "Epoch [3/5], Iter [2600/12500] Loss 2.5249\n",
            "Epoch [3/5], Iter [2700/12500] Loss 3.5526\n",
            "Epoch [3/5], Iter [2800/12500] Loss 1.8495\n",
            "Epoch [3/5], Iter [2900/12500] Loss 2.1102\n",
            "Epoch [3/5], Iter [3000/12500] Loss 2.2489\n",
            "Epoch [3/5], Iter [3100/12500] Loss 1.8042\n",
            "Epoch [3/5], Iter [3200/12500] Loss 2.1977\n",
            "Epoch [3/5], Iter [3300/12500] Loss 1.1131\n",
            "Epoch [3/5], Iter [3400/12500] Loss 2.1538\n",
            "Epoch [3/5], Iter [3500/12500] Loss 0.9836\n",
            "Epoch [3/5], Iter [3600/12500] Loss 1.2927\n",
            "Epoch [3/5], Iter [3700/12500] Loss 3.1424\n",
            "Epoch [3/5], Iter [3800/12500] Loss 1.9548\n",
            "Epoch [3/5], Iter [3900/12500] Loss 2.4648\n",
            "Epoch [3/5], Iter [4000/12500] Loss 2.2309\n",
            "Epoch [3/5], Iter [4100/12500] Loss 0.3353\n",
            "Epoch [3/5], Iter [4200/12500] Loss 1.8554\n",
            "Epoch [3/5], Iter [4300/12500] Loss 2.7777\n",
            "Epoch [3/5], Iter [4400/12500] Loss 2.9200\n",
            "Epoch [3/5], Iter [4500/12500] Loss 1.1901\n",
            "Epoch [3/5], Iter [4600/12500] Loss 1.1128\n",
            "Epoch [3/5], Iter [4700/12500] Loss 2.9244\n",
            "Epoch [3/5], Iter [4800/12500] Loss 1.7402\n",
            "Epoch [3/5], Iter [4900/12500] Loss 0.8972\n",
            "Epoch [3/5], Iter [5000/12500] Loss 1.4676\n",
            "Epoch [3/5], Iter [5100/12500] Loss 0.4732\n",
            "Epoch [3/5], Iter [5200/12500] Loss 2.5070\n",
            "Epoch [3/5], Iter [5300/12500] Loss 1.1678\n",
            "Epoch [3/5], Iter [5400/12500] Loss 3.4747\n",
            "Epoch [3/5], Iter [5500/12500] Loss 2.4577\n",
            "Epoch [3/5], Iter [5600/12500] Loss 1.1496\n",
            "Epoch [3/5], Iter [5700/12500] Loss 1.5863\n",
            "Epoch [3/5], Iter [5800/12500] Loss 1.4979\n",
            "Epoch [3/5], Iter [5900/12500] Loss 3.8914\n",
            "Epoch [3/5], Iter [6000/12500] Loss 2.4482\n",
            "Epoch [3/5], Iter [6100/12500] Loss 1.1861\n",
            "Epoch [3/5], Iter [6200/12500] Loss 1.4964\n",
            "Epoch [3/5], Iter [6300/12500] Loss 2.6847\n",
            "Epoch [3/5], Iter [6400/12500] Loss 2.0471\n",
            "Epoch [3/5], Iter [6500/12500] Loss 1.4715\n",
            "Epoch [3/5], Iter [6600/12500] Loss 1.1223\n",
            "Epoch [3/5], Iter [6700/12500] Loss 2.2371\n",
            "Epoch [3/5], Iter [6800/12500] Loss 3.1089\n",
            "Epoch [3/5], Iter [6900/12500] Loss 2.1106\n",
            "Epoch [3/5], Iter [7000/12500] Loss 1.5349\n",
            "Epoch [3/5], Iter [7100/12500] Loss 2.5614\n",
            "Epoch [3/5], Iter [7200/12500] Loss 0.7898\n",
            "Epoch [3/5], Iter [7300/12500] Loss 1.2249\n",
            "Epoch [3/5], Iter [7400/12500] Loss 2.9449\n",
            "Epoch [3/5], Iter [7500/12500] Loss 1.9397\n",
            "Epoch [3/5], Iter [7600/12500] Loss 0.2005\n",
            "Epoch [3/5], Iter [7700/12500] Loss 0.8874\n",
            "Epoch [3/5], Iter [7800/12500] Loss 1.0682\n",
            "Epoch [3/5], Iter [7900/12500] Loss 0.9379\n",
            "Epoch [3/5], Iter [8000/12500] Loss 2.0950\n",
            "Epoch [3/5], Iter [8100/12500] Loss 1.8305\n",
            "Epoch [3/5], Iter [8200/12500] Loss 2.4164\n",
            "Epoch [3/5], Iter [8300/12500] Loss 2.9572\n",
            "Epoch [3/5], Iter [8400/12500] Loss 2.7850\n",
            "Epoch [3/5], Iter [8500/12500] Loss 0.9903\n",
            "Epoch [3/5], Iter [8600/12500] Loss 1.3797\n",
            "Epoch [3/5], Iter [8700/12500] Loss 2.5395\n",
            "Epoch [3/5], Iter [8800/12500] Loss 0.2643\n",
            "Epoch [3/5], Iter [8900/12500] Loss 1.2618\n",
            "Epoch [3/5], Iter [9000/12500] Loss 2.0643\n",
            "Epoch [3/5], Iter [9100/12500] Loss 4.2369\n",
            "Epoch [3/5], Iter [9200/12500] Loss 3.0333\n",
            "Epoch [3/5], Iter [9300/12500] Loss 2.6694\n",
            "Epoch [3/5], Iter [9400/12500] Loss 1.7023\n",
            "Epoch [3/5], Iter [9500/12500] Loss 0.9032\n",
            "Epoch [3/5], Iter [9600/12500] Loss 1.8851\n",
            "Epoch [3/5], Iter [9700/12500] Loss 2.9165\n",
            "Epoch [3/5], Iter [9800/12500] Loss 1.8356\n",
            "Epoch [3/5], Iter [9900/12500] Loss 0.3454\n",
            "Epoch [3/5], Iter [10000/12500] Loss 1.9127\n",
            "Epoch [3/5], Iter [10100/12500] Loss 1.8666\n",
            "Epoch [3/5], Iter [10200/12500] Loss 1.7451\n",
            "Epoch [3/5], Iter [10300/12500] Loss 2.0871\n",
            "Epoch [3/5], Iter [10400/12500] Loss 1.2651\n",
            "Epoch [3/5], Iter [10500/12500] Loss 0.8871\n",
            "Epoch [3/5], Iter [10600/12500] Loss 2.4938\n",
            "Epoch [3/5], Iter [10700/12500] Loss 1.0647\n",
            "Epoch [3/5], Iter [10800/12500] Loss 2.8621\n",
            "Epoch [3/5], Iter [10900/12500] Loss 3.3913\n",
            "Epoch [3/5], Iter [11000/12500] Loss 2.2509\n",
            "Epoch [3/5], Iter [11100/12500] Loss 2.2844\n",
            "Epoch [3/5], Iter [11200/12500] Loss 0.9957\n",
            "Epoch [3/5], Iter [11300/12500] Loss 0.6724\n",
            "Epoch [3/5], Iter [11400/12500] Loss 2.2961\n",
            "Epoch [3/5], Iter [11500/12500] Loss 1.3494\n",
            "Epoch [3/5], Iter [11600/12500] Loss 5.3637\n",
            "Epoch [3/5], Iter [11700/12500] Loss 0.2381\n",
            "Epoch [3/5], Iter [11800/12500] Loss 1.0856\n",
            "Epoch [3/5], Iter [11900/12500] Loss 1.6282\n",
            "Epoch [3/5], Iter [12000/12500] Loss 1.0991\n",
            "Epoch [3/5], Iter [12100/12500] Loss 3.9796\n",
            "Epoch [3/5], Iter [12200/12500] Loss 4.1810\n",
            "Epoch [3/5], Iter [12300/12500] Loss 2.0723\n",
            "Epoch [3/5], Iter [12400/12500] Loss 1.8774\n",
            "Epoch [4/5], Iter [0/12500] Loss 2.3996\n",
            "Epoch [4/5], Iter [100/12500] Loss 2.9640\n",
            "Epoch [4/5], Iter [200/12500] Loss 1.3957\n",
            "Epoch [4/5], Iter [300/12500] Loss 1.6687\n",
            "Epoch [4/5], Iter [400/12500] Loss 2.3590\n",
            "Epoch [4/5], Iter [500/12500] Loss 0.7711\n",
            "Epoch [4/5], Iter [600/12500] Loss 2.7677\n",
            "Epoch [4/5], Iter [700/12500] Loss 1.6384\n",
            "Epoch [4/5], Iter [800/12500] Loss 2.5036\n",
            "Epoch [4/5], Iter [900/12500] Loss 1.4872\n",
            "Epoch [4/5], Iter [1000/12500] Loss 2.1548\n",
            "Epoch [4/5], Iter [1100/12500] Loss 2.7753\n",
            "Epoch [4/5], Iter [1200/12500] Loss 1.8737\n",
            "Epoch [4/5], Iter [1300/12500] Loss 0.6055\n",
            "Epoch [4/5], Iter [1400/12500] Loss 2.0295\n",
            "Epoch [4/5], Iter [1500/12500] Loss 3.4247\n",
            "Epoch [4/5], Iter [1600/12500] Loss 0.4640\n",
            "Epoch [4/5], Iter [1700/12500] Loss 2.4629\n",
            "Epoch [4/5], Iter [1800/12500] Loss 2.1649\n",
            "Epoch [4/5], Iter [1900/12500] Loss 2.7886\n",
            "Epoch [4/5], Iter [2000/12500] Loss 1.3249\n",
            "Epoch [4/5], Iter [2100/12500] Loss 3.0828\n",
            "Epoch [4/5], Iter [2200/12500] Loss 1.4863\n",
            "Epoch [4/5], Iter [2300/12500] Loss 0.9379\n",
            "Epoch [4/5], Iter [2400/12500] Loss 1.8945\n",
            "Epoch [4/5], Iter [2500/12500] Loss 4.2947\n",
            "Epoch [4/5], Iter [2600/12500] Loss 1.4946\n",
            "Epoch [4/5], Iter [2700/12500] Loss 0.6592\n",
            "Epoch [4/5], Iter [2800/12500] Loss 2.9918\n",
            "Epoch [4/5], Iter [2900/12500] Loss 0.8890\n",
            "Epoch [4/5], Iter [3000/12500] Loss 1.2696\n",
            "Epoch [4/5], Iter [3100/12500] Loss 1.5900\n",
            "Epoch [4/5], Iter [3200/12500] Loss 2.8999\n",
            "Epoch [4/5], Iter [3300/12500] Loss 0.5579\n",
            "Epoch [4/5], Iter [3400/12500] Loss 1.0434\n",
            "Epoch [4/5], Iter [3500/12500] Loss 0.6135\n",
            "Epoch [4/5], Iter [3600/12500] Loss 1.0525\n",
            "Epoch [4/5], Iter [3700/12500] Loss 1.1943\n",
            "Epoch [4/5], Iter [3800/12500] Loss 1.9180\n",
            "Epoch [4/5], Iter [3900/12500] Loss 0.7246\n",
            "Epoch [4/5], Iter [4000/12500] Loss 2.0761\n",
            "Epoch [4/5], Iter [4100/12500] Loss 3.1842\n",
            "Epoch [4/5], Iter [4200/12500] Loss 1.6523\n",
            "Epoch [4/5], Iter [4300/12500] Loss 0.0572\n",
            "Epoch [4/5], Iter [4400/12500] Loss 2.4960\n",
            "Epoch [4/5], Iter [4500/12500] Loss 2.9072\n",
            "Epoch [4/5], Iter [4600/12500] Loss 2.3375\n",
            "Epoch [4/5], Iter [4700/12500] Loss 2.7872\n",
            "Epoch [4/5], Iter [4800/12500] Loss 1.6537\n",
            "Epoch [4/5], Iter [4900/12500] Loss 3.0602\n",
            "Epoch [4/5], Iter [5000/12500] Loss 2.1322\n",
            "Epoch [4/5], Iter [5100/12500] Loss 0.8987\n",
            "Epoch [4/5], Iter [5200/12500] Loss 0.5679\n",
            "Epoch [4/5], Iter [5300/12500] Loss 0.8175\n",
            "Epoch [4/5], Iter [5400/12500] Loss 0.8205\n",
            "Epoch [4/5], Iter [5500/12500] Loss 1.9491\n",
            "Epoch [4/5], Iter [5600/12500] Loss 1.2393\n",
            "Epoch [4/5], Iter [5700/12500] Loss 2.6604\n",
            "Epoch [4/5], Iter [5800/12500] Loss 2.9166\n",
            "Epoch [4/5], Iter [5900/12500] Loss 1.1727\n",
            "Epoch [4/5], Iter [6000/12500] Loss 0.7898\n",
            "Epoch [4/5], Iter [6100/12500] Loss 0.7507\n",
            "Epoch [4/5], Iter [6200/12500] Loss 1.0917\n",
            "Epoch [4/5], Iter [6300/12500] Loss 1.1688\n",
            "Epoch [4/5], Iter [6400/12500] Loss 1.7402\n",
            "Epoch [4/5], Iter [6500/12500] Loss 1.7713\n",
            "Epoch [4/5], Iter [6600/12500] Loss 2.1539\n",
            "Epoch [4/5], Iter [6700/12500] Loss 1.3772\n",
            "Epoch [4/5], Iter [6800/12500] Loss 1.1810\n",
            "Epoch [4/5], Iter [6900/12500] Loss 2.2107\n",
            "Epoch [4/5], Iter [7000/12500] Loss 1.3353\n",
            "Epoch [4/5], Iter [7100/12500] Loss 1.7902\n",
            "Epoch [4/5], Iter [7200/12500] Loss 2.6328\n",
            "Epoch [4/5], Iter [7300/12500] Loss 2.5630\n",
            "Epoch [4/5], Iter [7400/12500] Loss 2.3369\n",
            "Epoch [4/5], Iter [7500/12500] Loss 2.3150\n",
            "Epoch [4/5], Iter [7600/12500] Loss 0.7275\n",
            "Epoch [4/5], Iter [7700/12500] Loss 1.3303\n",
            "Epoch [4/5], Iter [7800/12500] Loss 1.7289\n",
            "Epoch [4/5], Iter [7900/12500] Loss 0.8173\n",
            "Epoch [4/5], Iter [8000/12500] Loss 2.0515\n",
            "Epoch [4/5], Iter [8100/12500] Loss 1.2532\n",
            "Epoch [4/5], Iter [8200/12500] Loss 1.7456\n",
            "Epoch [4/5], Iter [8300/12500] Loss 3.7358\n",
            "Epoch [4/5], Iter [8400/12500] Loss 2.7637\n",
            "Epoch [4/5], Iter [8500/12500] Loss 1.9006\n",
            "Epoch [4/5], Iter [8600/12500] Loss 1.9979\n",
            "Epoch [4/5], Iter [8700/12500] Loss 2.9017\n",
            "Epoch [4/5], Iter [8800/12500] Loss 0.5804\n",
            "Epoch [4/5], Iter [8900/12500] Loss 2.2612\n",
            "Epoch [4/5], Iter [9000/12500] Loss 1.4284\n",
            "Epoch [4/5], Iter [9100/12500] Loss 1.2800\n",
            "Epoch [4/5], Iter [9200/12500] Loss 3.0410\n",
            "Epoch [4/5], Iter [9300/12500] Loss 2.1027\n",
            "Epoch [4/5], Iter [9400/12500] Loss 1.2124\n",
            "Epoch [4/5], Iter [9500/12500] Loss 1.6992\n",
            "Epoch [4/5], Iter [9600/12500] Loss 3.0266\n",
            "Epoch [4/5], Iter [9700/12500] Loss 2.4937\n",
            "Epoch [4/5], Iter [9800/12500] Loss 1.8322\n",
            "Epoch [4/5], Iter [9900/12500] Loss 2.5272\n",
            "Epoch [4/5], Iter [10000/12500] Loss 1.4442\n",
            "Epoch [4/5], Iter [10100/12500] Loss 1.8551\n",
            "Epoch [4/5], Iter [10200/12500] Loss 1.5918\n",
            "Epoch [4/5], Iter [10300/12500] Loss 0.2490\n",
            "Epoch [4/5], Iter [10400/12500] Loss 1.1553\n",
            "Epoch [4/5], Iter [10500/12500] Loss 1.3272\n",
            "Epoch [4/5], Iter [10600/12500] Loss 2.5586\n",
            "Epoch [4/5], Iter [10700/12500] Loss 1.4296\n",
            "Epoch [4/5], Iter [10800/12500] Loss 3.3155\n",
            "Epoch [4/5], Iter [10900/12500] Loss 1.3322\n",
            "Epoch [4/5], Iter [11000/12500] Loss 1.6059\n",
            "Epoch [4/5], Iter [11100/12500] Loss 0.9278\n",
            "Epoch [4/5], Iter [11200/12500] Loss 1.8297\n",
            "Epoch [4/5], Iter [11300/12500] Loss 1.4443\n",
            "Epoch [4/5], Iter [11400/12500] Loss 2.0468\n",
            "Epoch [4/5], Iter [11500/12500] Loss 1.7141\n",
            "Epoch [4/5], Iter [11600/12500] Loss 1.8688\n",
            "Epoch [4/5], Iter [11700/12500] Loss 1.5854\n",
            "Epoch [4/5], Iter [11800/12500] Loss 1.4159\n",
            "Epoch [4/5], Iter [11900/12500] Loss 2.6002\n",
            "Epoch [4/5], Iter [12000/12500] Loss 2.5383\n",
            "Epoch [4/5], Iter [12100/12500] Loss 2.0282\n",
            "Epoch [4/5], Iter [12200/12500] Loss 1.7082\n",
            "Epoch [4/5], Iter [12300/12500] Loss 1.9057\n",
            "Epoch [4/5], Iter [12400/12500] Loss 1.2238\n",
            "Epoch [5/5], Iter [0/12500] Loss 1.5869\n",
            "Epoch [5/5], Iter [100/12500] Loss 1.1198\n",
            "Epoch [5/5], Iter [200/12500] Loss 1.8084\n",
            "Epoch [5/5], Iter [300/12500] Loss 2.1286\n",
            "Epoch [5/5], Iter [400/12500] Loss 1.4847\n",
            "Epoch [5/5], Iter [500/12500] Loss 0.6528\n",
            "Epoch [5/5], Iter [600/12500] Loss 1.2163\n",
            "Epoch [5/5], Iter [700/12500] Loss 1.4488\n",
            "Epoch [5/5], Iter [800/12500] Loss 1.5707\n",
            "Epoch [5/5], Iter [900/12500] Loss 1.4432\n",
            "Epoch [5/5], Iter [1000/12500] Loss 2.1736\n",
            "Epoch [5/5], Iter [1100/12500] Loss 1.6662\n",
            "Epoch [5/5], Iter [1200/12500] Loss 2.7969\n",
            "Epoch [5/5], Iter [1300/12500] Loss 1.8334\n",
            "Epoch [5/5], Iter [1400/12500] Loss 2.3660\n",
            "Epoch [5/5], Iter [1500/12500] Loss 1.2255\n",
            "Epoch [5/5], Iter [1600/12500] Loss 0.7732\n",
            "Epoch [5/5], Iter [1700/12500] Loss 1.4792\n",
            "Epoch [5/5], Iter [1800/12500] Loss 2.0241\n",
            "Epoch [5/5], Iter [1900/12500] Loss 3.9492\n",
            "Epoch [5/5], Iter [2000/12500] Loss 2.3281\n",
            "Epoch [5/5], Iter [2100/12500] Loss 1.2939\n",
            "Epoch [5/5], Iter [2200/12500] Loss 1.3415\n",
            "Epoch [5/5], Iter [2300/12500] Loss 2.8537\n",
            "Epoch [5/5], Iter [2400/12500] Loss 1.8759\n",
            "Epoch [5/5], Iter [2500/12500] Loss 2.6501\n",
            "Epoch [5/5], Iter [2600/12500] Loss 2.1700\n",
            "Epoch [5/5], Iter [2700/12500] Loss 1.2481\n",
            "Epoch [5/5], Iter [2800/12500] Loss 1.9941\n",
            "Epoch [5/5], Iter [2900/12500] Loss 1.2634\n",
            "Epoch [5/5], Iter [3000/12500] Loss 1.7318\n",
            "Epoch [5/5], Iter [3100/12500] Loss 3.6125\n",
            "Epoch [5/5], Iter [3200/12500] Loss 1.5375\n",
            "Epoch [5/5], Iter [3300/12500] Loss 1.3880\n",
            "Epoch [5/5], Iter [3400/12500] Loss 3.8174\n",
            "Epoch [5/5], Iter [3500/12500] Loss 0.6843\n",
            "Epoch [5/5], Iter [3600/12500] Loss 1.8302\n",
            "Epoch [5/5], Iter [3700/12500] Loss 1.6254\n",
            "Epoch [5/5], Iter [3800/12500] Loss 1.3423\n",
            "Epoch [5/5], Iter [3900/12500] Loss 1.3108\n",
            "Epoch [5/5], Iter [4000/12500] Loss 1.7285\n",
            "Epoch [5/5], Iter [4100/12500] Loss 2.4078\n",
            "Epoch [5/5], Iter [4200/12500] Loss 1.3886\n",
            "Epoch [5/5], Iter [4300/12500] Loss 3.0827\n",
            "Epoch [5/5], Iter [4400/12500] Loss 1.3649\n",
            "Epoch [5/5], Iter [4500/12500] Loss 1.0676\n",
            "Epoch [5/5], Iter [4600/12500] Loss 2.2191\n",
            "Epoch [5/5], Iter [4700/12500] Loss 0.8591\n",
            "Epoch [5/5], Iter [4800/12500] Loss 3.8735\n",
            "Epoch [5/5], Iter [4900/12500] Loss 1.9962\n",
            "Epoch [5/5], Iter [5000/12500] Loss 2.8328\n",
            "Epoch [5/5], Iter [5100/12500] Loss 1.0209\n",
            "Epoch [5/5], Iter [5200/12500] Loss 1.7212\n",
            "Epoch [5/5], Iter [5300/12500] Loss 0.2970\n",
            "Epoch [5/5], Iter [5400/12500] Loss 3.4725\n",
            "Epoch [5/5], Iter [5500/12500] Loss 1.5315\n",
            "Epoch [5/5], Iter [5600/12500] Loss 1.3129\n",
            "Epoch [5/5], Iter [5700/12500] Loss 1.6957\n",
            "Epoch [5/5], Iter [5800/12500] Loss 1.6388\n",
            "Epoch [5/5], Iter [5900/12500] Loss 1.9853\n",
            "Epoch [5/5], Iter [6000/12500] Loss 1.2309\n",
            "Epoch [5/5], Iter [6100/12500] Loss 1.2908\n",
            "Epoch [5/5], Iter [6200/12500] Loss 2.2720\n",
            "Epoch [5/5], Iter [6300/12500] Loss 0.8970\n",
            "Epoch [5/5], Iter [6400/12500] Loss 1.4694\n",
            "Epoch [5/5], Iter [6500/12500] Loss 1.0655\n",
            "Epoch [5/5], Iter [6600/12500] Loss 2.1547\n",
            "Epoch [5/5], Iter [6700/12500] Loss 2.6539\n",
            "Epoch [5/5], Iter [6800/12500] Loss 1.0677\n",
            "Epoch [5/5], Iter [6900/12500] Loss 3.1722\n",
            "Epoch [5/5], Iter [7000/12500] Loss 1.3134\n",
            "Epoch [5/5], Iter [7100/12500] Loss 1.0318\n",
            "Epoch [5/5], Iter [7200/12500] Loss 0.7073\n",
            "Epoch [5/5], Iter [7300/12500] Loss 1.6421\n",
            "Epoch [5/5], Iter [7400/12500] Loss 3.2170\n",
            "Epoch [5/5], Iter [7500/12500] Loss 0.7840\n",
            "Epoch [5/5], Iter [7600/12500] Loss 0.5555\n",
            "Epoch [5/5], Iter [7700/12500] Loss 0.7888\n",
            "Epoch [5/5], Iter [7800/12500] Loss 2.6976\n",
            "Epoch [5/5], Iter [7900/12500] Loss 0.8173\n",
            "Epoch [5/5], Iter [8000/12500] Loss 1.6772\n",
            "Epoch [5/5], Iter [8100/12500] Loss 2.6106\n",
            "Epoch [5/5], Iter [8200/12500] Loss 0.2663\n",
            "Epoch [5/5], Iter [8300/12500] Loss 1.5372\n",
            "Epoch [5/5], Iter [8400/12500] Loss 1.7134\n",
            "Epoch [5/5], Iter [8500/12500] Loss 1.5980\n",
            "Epoch [5/5], Iter [8600/12500] Loss 2.4110\n",
            "Epoch [5/5], Iter [8700/12500] Loss 1.4137\n",
            "Epoch [5/5], Iter [8800/12500] Loss 1.3247\n",
            "Epoch [5/5], Iter [8900/12500] Loss 1.6566\n",
            "Epoch [5/5], Iter [9000/12500] Loss 3.4306\n",
            "Epoch [5/5], Iter [9100/12500] Loss 3.5926\n",
            "Epoch [5/5], Iter [9200/12500] Loss 1.6607\n",
            "Epoch [5/5], Iter [9300/12500] Loss 2.5548\n",
            "Epoch [5/5], Iter [9400/12500] Loss 2.7041\n",
            "Epoch [5/5], Iter [9500/12500] Loss 1.7477\n",
            "Epoch [5/5], Iter [9600/12500] Loss 0.9289\n",
            "Epoch [5/5], Iter [9700/12500] Loss 0.6857\n",
            "Epoch [5/5], Iter [9800/12500] Loss 3.1690\n",
            "Epoch [5/5], Iter [9900/12500] Loss 1.7210\n",
            "Epoch [5/5], Iter [10000/12500] Loss 1.0699\n",
            "Epoch [5/5], Iter [10100/12500] Loss 0.4853\n",
            "Epoch [5/5], Iter [10200/12500] Loss 1.1638\n",
            "Epoch [5/5], Iter [10300/12500] Loss 1.9842\n",
            "Epoch [5/5], Iter [10400/12500] Loss 0.0558\n",
            "Epoch [5/5], Iter [10500/12500] Loss 1.0685\n",
            "Epoch [5/5], Iter [10600/12500] Loss 2.5609\n",
            "Epoch [5/5], Iter [10700/12500] Loss 0.2072\n",
            "Epoch [5/5], Iter [10800/12500] Loss 2.3603\n",
            "Epoch [5/5], Iter [10900/12500] Loss 1.0829\n",
            "Epoch [5/5], Iter [11000/12500] Loss 0.6542\n",
            "Epoch [5/5], Iter [11100/12500] Loss 1.0721\n",
            "Epoch [5/5], Iter [11200/12500] Loss 0.8361\n",
            "Epoch [5/5], Iter [11300/12500] Loss 1.4889\n",
            "Epoch [5/5], Iter [11400/12500] Loss 1.7543\n",
            "Epoch [5/5], Iter [11500/12500] Loss 1.2735\n",
            "Epoch [5/5], Iter [11600/12500] Loss 3.5220\n",
            "Epoch [5/5], Iter [11700/12500] Loss 1.5856\n",
            "Epoch [5/5], Iter [11800/12500] Loss 0.7865\n",
            "Epoch [5/5], Iter [11900/12500] Loss 2.8476\n",
            "Epoch [5/5], Iter [12000/12500] Loss 0.9315\n",
            "Epoch [5/5], Iter [12100/12500] Loss 3.0991\n",
            "Epoch [5/5], Iter [12200/12500] Loss 2.6055\n",
            "Epoch [5/5], Iter [12300/12500] Loss 0.4690\n",
            "Epoch [5/5], Iter [12400/12500] Loss 1.3313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D8YMR6nZg-ZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f30097f0-6753-474f-d96f-cb19945d28f2"
      },
      "cell_type": "code",
      "source": [
        "vgg16.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "for img, label in test_loader:\n",
        "    images = Variable(img.cuda())\n",
        "    labels = Variable(label.cuda())\n",
        "\n",
        "    out = vgg16(images)\n",
        "    _, predicted = torch.max(out.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    \n",
        "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(vgg16.state_dict(), 'model_nn_Adam.ckpt')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 55.42 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "68em5_Dag-XY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1369524-6f56-4e03-ddbd-0b79a81db88b"
      },
      "cell_type": "code",
      "source": [
        "vgg16.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "for img, label in test_loader:\n",
        "    images = img.to(device)\n",
        "    labels = label.to(device)\n",
        "\n",
        "    out = vgg16(images)\n",
        "    _, predicted = torch.max(out.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    \n",
        "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(vgg16.state_dict(), 'model_nn_Adam.ckpt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 55.22 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_whBW9kBg-VX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ypLioUUFg-TL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KADxdMyUg-PY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaQeIyl6g-F6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P1Io_MQ5g9xi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}